{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class LunarLander:\n",
    "    def __init__(self):\n",
    "        # Environment setup\n",
    "        self.position = np.array([0.0, 100.0])  # Initial position, 100 units above the surface\n",
    "        self.velocity = np.array([0.0, -10.0])  # Initial downward velocity\n",
    "        self.fuel = 100.0  # Starting fuel amount\n",
    "        \n",
    "        # Constants representing the environment\n",
    "        self.gravity = np.array([0.0, -1.62])  # Gravity on the moon in m/s^2\n",
    "        self.thrust_power = 10.0  # Thrust provided by the lander's engine\n",
    "        self.fuel_consumption_per_action = 10.0  # Fuel consumption per thrust action\n",
    "\n",
    "    def apply_gravity(self):\n",
    "        \"\"\"Apply gravity to the lander's velocity, representing the environment's effect.\"\"\"\n",
    "        self.velocity += self.gravity\n",
    "\n",
    "    def apply_thrust(self):\n",
    "        \"\"\"Agent action: Apply thrust to counteract gravity, consuming fuel.\"\"\"\n",
    "        if self.fuel > 0:\n",
    "            self.velocity += np.array([0.0, self.thrust_power])\n",
    "            self.fuel -= self.fuel_consumption_per_action\n",
    "\n",
    "    def update_position(self):\n",
    "        \"\"\"Update the lander's position based on its velocity, simulating environmental physics.\"\"\"\n",
    "        self.position += self.velocity\n",
    "\n",
    "    def simulate_step(self, action):\n",
    "        \"\"\"Simulate a single time step given an agent's action.\n",
    "        \n",
    "        This method integrates the environment's response (gravity) and the agent's actions (thrust) to update the state.\n",
    "        \"\"\"\n",
    "        # Environment effect: gravity\n",
    "        self.apply_gravity()\n",
    "\n",
    "        # Agent action: apply thrust if chosen\n",
    "        if action == \"thrust\":\n",
    "            self.apply_thrust()\n",
    "\n",
    "        # Update agent's position in the environment\n",
    "        self.update_position()\n",
    "\n",
    "        # Check for landing or crash to determine the outcome\n",
    "        if self.position[1] <= 0:\n",
    "            if np.abs(self.velocity[1]) <= 5:  # Considered a successful landing if velocity is low\n",
    "                return \"landed\"\n",
    "            else:\n",
    "                return \"crashed\"\n",
    "        return \"flying\"\n",
    "\n",
    "# Note: The search algorithm would interact with the LunarLander class by iteratively calling simulate_step()\n",
    "# with different sequences of actions, evaluating outcomes, and selecting the best sequence to achieve a successful landing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No landing sequence found within the depth limit.\n"
     ]
    }
   ],
   "source": [
    "class LunarLanderSearch(LunarLander):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.best_sequence = []\n",
    "        self.min_fuel = float('inf')\n",
    "\n",
    "    def search(self, sequence, max_depth, current_depth=0):\n",
    "        if current_depth > max_depth or self.fuel < 0:\n",
    "            return False\n",
    "\n",
    "        if self.position[1] <= 0:\n",
    "            if self.velocity[1] > -5 and self.fuel < self.min_fuel:\n",
    "                self.min_fuel = self.fuel\n",
    "                self.best_sequence = sequence.copy()\n",
    "            return self.velocity[1] > -5\n",
    "\n",
    "        # Try applying thrust\n",
    "        self.simulate_step(\"thrust\")\n",
    "        sequence.append(\"thrust\")\n",
    "        if self.search(sequence, max_depth, current_depth + 1):\n",
    "            return True\n",
    "        sequence.pop()\n",
    "        self.load_state(current_depth)\n",
    "\n",
    "        # Try not applying thrust\n",
    "        self.simulate_step(\"no thrust\")\n",
    "        sequence.append(\"no thrust\")\n",
    "        if self.search(sequence, max_depth, current_depth + 1):\n",
    "            return True\n",
    "        sequence.pop()\n",
    "        self.load_state(current_depth)\n",
    "\n",
    "        return False\n",
    "\n",
    "    def load_state(self, step):\n",
    "        # This function should load the lander's state to the state before the given step\n",
    "        # For simplicity, let's assume it resets to the initial state for now\n",
    "        self.__init__()\n",
    "\n",
    "# Example of using the search algorithm\n",
    "lander_search = LunarLanderSearch()\n",
    "if lander_search.search([], 10):  # Set a max depth of 10 for this example\n",
    "    print(\"Found a landing sequence:\", lander_search.best_sequence)\n",
    "else:\n",
    "    print(\"No landing sequence found within the depth limit.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, position, velocity, fuel, actions):\n",
    "        self.position = position\n",
    "        self.velocity = velocity\n",
    "        self.fuel = fuel\n",
    "        self.actions = actions  # Path taken to reach this node\n",
    "        self.g = len(actions) * 10  # Cost function: Assume each action has a cost (e.g., fuel)\n",
    "        self.h = self.heuristic()  # Heuristic function\n",
    "        self.f = self.g + self.h\n",
    "\n",
    "    def heuristic(self):\n",
    "        # Simple heuristic: prioritize lower altitude and lower velocity\n",
    "        # Adjust this to fit the problem requirements better\n",
    "        return self.position[1] + abs(self.velocity[1])\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return self.f < other.f\n",
    "\n",
    "def simulate_action(node, action):\n",
    "    \"\"\"\n",
    "    Simulates the effect of an action on the lunar lander's current state.\n",
    "    \n",
    "    :param node: The current node representing the lander's state.\n",
    "    :param action: The action to simulate (\"thrust\" or \"no thrust\").\n",
    "    :return: A tuple of the new position, velocity, and fuel.\n",
    "    \"\"\"\n",
    "    # Copy the current state to avoid modifying it directly\n",
    "    position = node.position.copy()\n",
    "    velocity = node.velocity.copy()\n",
    "    fuel = node.fuel\n",
    "    \n",
    "    # Apply gravity (constant effect)\n",
    "    gravity_effect = np.array([0.0, -1.62])\n",
    "    velocity += gravity_effect\n",
    "    \n",
    "    # Apply action effect\n",
    "    if action == \"thrust\" and fuel >= 10:  # Assuming each thrust action consumes 10 units of fuel\n",
    "        thrust_effect = np.array([0.0, 10.0])  # Thrust counteracts gravity\n",
    "        velocity += thrust_effect\n",
    "        fuel -= 10  # Subtract fuel used\n",
    "    \n",
    "    # Update position based on the new velocity\n",
    "    position += velocity\n",
    "    \n",
    "    return position, velocity, fuel\n",
    "\n",
    "\n",
    "def a_star_search(lander):\n",
    "    open_set = []\n",
    "    start_node = Node(lander.position, lander.velocity, lander.fuel, [])\n",
    "    heapq.heappush(open_set, start_node)\n",
    "\n",
    "    while open_set:\n",
    "        current_node = heapq.heappop(open_set)\n",
    "\n",
    "        # Check if landed\n",
    "        if current_node.position[1] <= 0 and abs(current_node.velocity[1]) < 5:\n",
    "            return current_node.actions  # Return the path to landing\n",
    "\n",
    "        # Expand node by simulating possible actions\n",
    "        for action in [\"thrust\", \"no thrust\"]:\n",
    "            # Simulate the action to create a new state/node\n",
    "            # Note: This requires implementing a function to simulate actions without altering the original lander\n",
    "            new_position, new_velocity, new_fuel = simulate_action(current_node, action)\n",
    "            if new_fuel >= 0:  # Check if action is possible\n",
    "                new_actions = current_node.actions + [action]\n",
    "                new_node = Node(new_position, new_velocity, new_fuel, new_actions)\n",
    "                heapq.heappush(open_set, new_node)\n",
    "\n",
    "    return None  # No path found\n",
    "\n",
    "# Note: `simulate_action` function needs to be implemented to apply actions to a node/state\n",
    "# without altering the original lander's state. This involves duplicating some of the logic\n",
    "# from the LunarLander class to simulate physics for each potential action.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
